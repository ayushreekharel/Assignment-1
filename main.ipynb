{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d25763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import filters, measure, morphology\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac762c5c",
   "metadata": {},
   "source": [
    "TASK1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4412b",
   "metadata": {},
   "source": [
    "Loading the ct images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b45005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ct_image(filepath):\n",
    "    ct_img = nib.load(filepath)\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    return ct_data, ct_img.affine, ct_img.header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be10941",
   "metadata": {},
   "source": [
    "Segmenting the bones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_bones(ct_data, femur_threshold=300, tibia_threshold=300):\n",
    "\n",
    "    \n",
    "    \n",
    "    depth, height, width = ct_data.shape\n",
    "    print(f\"CT volume dimensions: {depth}x{height}x{width}\")  #to get the image dimension \n",
    "    \n",
    "    segmented_femur = np.zeros_like(ct_data, dtype=bool)\n",
    "    segmented_tibia = np.zeros_like(ct_data, dtype=bool)\n",
    "    \n",
    "\n",
    "    print(f\"Using threshold value: {femur_threshold} HU for bones\")  #creating the initial bone mask using threshold\n",
    "    bone_mask = ct_data > femur_threshold\n",
    "    \n",
    "    # Cleaning up the mask\n",
    "    bone_mask = morphology.remove_small_objects(bone_mask, min_size=50)\n",
    "    bone_mask = morphology.binary_closing(bone_mask, morphology.ball(1))\n",
    "    \n",
    "    # Finding a good slice to analyze (where both bones are visible)\n",
    "    # Calculate sum across each slice to find slices with significant bone content\n",
    "    slice_bone_content = np.sum(bone_mask, axis=(1, 2))\n",
    "    significant_slices = np.where(slice_bone_content > 100)[0]\n",
    "    \n",
    "    if len(significant_slices) == 0:\n",
    "        print(\"No significant bone content found. Adjusting threshold...\")\n",
    "        # If no significant bone content is found then go with the lower threshold\n",
    "        bone_mask = ct_data > (femur_threshold - 100)\n",
    "        bone_mask = morphology.remove_small_objects(bone_mask, min_size=50)\n",
    "        slice_bone_content = np.sum(bone_mask, axis=(1, 2))\n",
    "        significant_slices = np.where(slice_bone_content > 100)[0]\n",
    "    \n",
    "    print(f\"Found {len(significant_slices)} slices with significant bone content\")\n",
    "    \n",
    "    # If we still can't find significant slices, use anatomical approach\n",
    "    if len(significant_slices) == 0:\n",
    "        print(\"Still no significant bone content found. Using anatomical approach...\")\n",
    "        # Divide the volume into anatomical regions\n",
    "        femur_region = slice(0, depth // 2)  # Upper half for femur\n",
    "        tibia_region = slice(depth // 2, depth)  # Lower half for tibia\n",
    "        \n",
    "        # Apply different thresholds for each region\n",
    "        segmented_femur[femur_region] = ct_data[femur_region] > femur_threshold\n",
    "        segmented_tibia[tibia_region] = ct_data[tibia_region] > tibia_threshold\n",
    "    else:\n",
    "        # Analyze each significant slice to identify femur and tibia\n",
    "        for slice_idx in significant_slices:\n",
    "            slice_mask = bone_mask[slice_idx]\n",
    "            labeled_slice, num_labels = measure.label(slice_mask, return_num=True)\n",
    "            \n",
    "            if num_labels < 1:\n",
    "                continue\n",
    "                \n",
    "            # Get region properties\n",
    "            regions = measure.regionprops(labeled_slice)\n",
    "            \n",
    "            # For simplicity with this particular CT orientation:\n",
    "            # Based on the image shown, the femur appears on the right side (higher x values)\n",
    "            # and tibia appears on the left side (lower x values)\n",
    "            # This is specific to the current dataset orientation\n",
    "            \n",
    "            # Sort regions by centroid x-coordinate (horizontal position)\n",
    "            regions.sort(key=lambda r: r.centroid[1], reverse=True)  # Sort right to left\n",
    "            \n",
    "            # Apply to specific regions (may need adjustment based on actual image orientation)\n",
    "            for i, region in enumerate(regions):\n",
    "                if i == 0:  # Right-most region (assumed to be femur in this orientation)\n",
    "                    segmented_femur[slice_idx][labeled_slice == region.label] = True\n",
    "                elif i == 1:  # Second right-most region (assumed to be tibia in this orientation)\n",
    "                    segmented_tibia[slice_idx][labeled_slice == region.label] = True\n",
    "    \n",
    "    # Clean up the segmentation masks\n",
    "    segmented_femur = morphology.binary_closing(segmented_femur, morphology.ball(2))\n",
    "    segmented_tibia = morphology.binary_closing(segmented_tibia, morphology.ball(2))\n",
    "    \n",
    "    # Remove small disconnected components\n",
    "    segmented_femur = morphology.remove_small_objects(segmented_femur, min_size=100)\n",
    "    segmented_tibia = morphology.remove_small_objects(segmented_tibia, min_size=100)\n",
    "    \n",
    "    # If the femur or tibia mask is empty, try a different approach\n",
    "    if not np.any(segmented_femur) or not np.any(segmented_tibia):\n",
    "        print(\"Warning: One or both segmentation masks are empty. Trying alternative approach...\")\n",
    "        # Use anatomical knowledge about the rough positions of femur and tibia in this CT\n",
    "        # For this specific orientation, divide the image into regions\n",
    "        \n",
    "        # For this specific dataset, create spatial masks based on the approximate locations\n",
    "        # These values may need adjustment based on the actual data\n",
    "        height_mid = height // 2\n",
    "        width_mid = width // 2\n",
    "        \n",
    "        # Create spatial masks for femur (right upper quadrant) and tibia (right lower quadrant)\n",
    "        femur_spatial_mask = np.zeros((depth, height, width), dtype=bool)\n",
    "        tibia_spatial_mask = np.zeros((depth, height, width), dtype=bool)\n",
    "        \n",
    "        # Define spatial regions (adjust based on CT orientation)\n",
    "        femur_spatial_mask[:, :height_mid, width_mid:] = True  # Upper right quadrant\n",
    "        tibia_spatial_mask[:, height_mid:, width_mid:] = True  # Lower right quadrant\n",
    "        \n",
    "        # Combine spatial masks with intensity threshold\n",
    "        segmented_femur = (ct_data > femur_threshold) & femur_spatial_mask\n",
    "        segmented_tibia = (ct_data > tibia_threshold) & tibia_spatial_mask\n",
    "        \n",
    "        # Clean up\n",
    "        segmented_femur = morphology.remove_small_objects(segmented_femur, min_size=100)\n",
    "        segmented_tibia = morphology.remove_small_objects(segmented_tibia, min_size=100)\n",
    "    \n",
    "    print(\"Bone segmentation completed\")\n",
    "    return segmented_femur, segmented_tibia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8274620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save the segmentation \n",
    "def save_segmentation(segmentation, affine, header, output_path):\n",
    "    print(f\"Saving segmentation to {output_path}\")\n",
    "    # Convert boolean to int (0 and 1)\n",
    "    segmentation_int = segmentation.astype(np.int16)\n",
    "    # Create NIfTI image\n",
    "    nii_img = nib.Nifti1Image(segmentation_int, affine, header)\n",
    "    # Save as nii.gz\n",
    "    nib.save(nii_img, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaaa35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to visualize the segments \n",
    "def visualize_segmentation(ct_data, femur_mask, tibia_mask, slice_num=None):\n",
    "    if slice_num is None:\n",
    "        # Find a slice with both bones visible\n",
    "        combined_mask = femur_mask | tibia_mask\n",
    "        slice_indices = np.where(combined_mask.sum(axis=(1, 2)) > 0)[0]\n",
    "        if len(slice_indices) > 0:\n",
    "            slice_num = slice_indices[len(slice_indices) // 2]  # Middle slice with bones\n",
    "        else:\n",
    "            slice_num = ct_data.shape[0] // 2  # Default to middle slice\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original CT slice\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(ct_data[slice_num], cmap='gray')\n",
    "    plt.title('Original CT Slice')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Get the min/max values for consistent display\n",
    "    vmin = np.min(ct_data[slice_num])\n",
    "    vmax = np.max(ct_data[slice_num])\n",
    "    \n",
    "    # Femur segmentation with clear highlight\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(ct_data[slice_num], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Create a highlighted overlay for femur\n",
    "    femur_overlay = np.zeros_like(ct_data[slice_num], dtype=float)\n",
    "    femur_overlay[femur_mask[slice_num]] = 1.0\n",
    "    \n",
    "    # Apply the overlay with high contrast\n",
    "    plt.imshow(femur_overlay, alpha=0.7, cmap='Reds')\n",
    "    plt.title('Femur Segmentation')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Tibia segmentation with clear highlight\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(ct_data[slice_num], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # Create a highlighted overlay for tibia\n",
    "    tibia_overlay = np.zeros_like(ct_data[slice_num], dtype=float)\n",
    "    tibia_overlay[tibia_mask[slice_num]] = 1.0\n",
    "    \n",
    "    # Apply the overlay with high contrast\n",
    "    plt.imshow(tibia_overlay, alpha=0.7, cmap='Blues')\n",
    "    plt.title('Tibia Segmentation')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('segmentation_visualization.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print the segmentation statistics\n",
    "    femur_voxels = np.sum(femur_mask)\n",
    "    tibia_voxels = np.sum(tibia_mask)\n",
    "    print(f\"Femur segmentation: {femur_voxels} voxels\")\n",
    "    print(f\"Tibia segmentation: {tibia_voxels} voxels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7027db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT volume dimensions: 512x512x216\n",
      "Using threshold value: 300 HU for bones\n",
      "Found 183 slices with significant bone content\n",
      "Bone segmentation completed\n",
      "Saving segmentation to segmented_femur.nii.gz\n",
      "Saving segmentation to segmented_tibia.nii.gz\n",
      "Femur segmentation: 75612 voxels\n",
      "Tibia segmentation: 36776 voxels\n",
      "Bone segmentation task completed successfully\n",
      "A good slice for visualization is: 403\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Input and output paths\n",
    "    input_path = \"./3702_left_knee.nii\"  # Replace with actual path\n",
    "    output_femur_path = \"segmented_femur.nii.gz\"\n",
    "    output_tibia_path = \"segmented_tibia.nii.gz\"\n",
    "    \n",
    "    # Step 1: Load the CT image\n",
    "    ct_data, affine, header = load_ct_image(input_path)\n",
    "    \n",
    "    # Step 2: Segment the bones\n",
    "    # Using a higher threshold of 300 HU which is more appropriate for dense bone\n",
    "    femur_mask, tibia_mask = segment_bones(ct_data, femur_threshold=300, tibia_threshold=300)\n",
    "    \n",
    "    # Step 3: Save the segmentations\n",
    "    save_segmentation(femur_mask, affine, header, output_femur_path)\n",
    "    save_segmentation(tibia_mask, affine, header, output_tibia_path)\n",
    "    \n",
    "    # Step 4: Visualize the results\n",
    "    visualize_segmentation(ct_data, femur_mask, tibia_mask)\n",
    "    \n",
    "    print(\"Bone segmentation task completed successfully\")\n",
    "    \n",
    "    # Optional: Display a cross-section where both bones are visible\n",
    "    # Find a good slice to show\n",
    "    combined_mask = femur_mask | tibia_mask\n",
    "    slice_indices = np.where(combined_mask.sum(axis=(1, 2)) > 0)[0]\n",
    "    if len(slice_indices) > 0:\n",
    "        good_slice = slice_indices[len(slice_indices) // 2]\n",
    "        print(f\"A good slice for visualization is: {good_slice}\")\n",
    "    else:\n",
    "        print(\"No slices with both bones found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79452464",
   "metadata": {},
   "source": [
    "TASK 1.2 & 1.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce6c3d",
   "metadata": {},
   "source": [
    "Loading the data and saving the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d0c4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii(file_path):\n",
    "    \n",
    "    nii_img = nib.load(file_path)\n",
    "    return nii_img.get_fdata(), nii_img.affine, nii_img.header\n",
    "\n",
    "def save_nii(data, affine, header, output_path):\n",
    "    \n",
    "    nii_img = nib.Nifti1Image(data, affine, header)\n",
    "    nib.save(nii_img, output_path)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e18ba6",
   "metadata": {},
   "source": [
    "For contour expansion and randomized contour adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78b2c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage\n",
    "def expand_mask(mask, expansion_mm, voxel_spacing):\n",
    "\n",
    "    # Convert expansion from mm to voxels in each dimension\n",
    "    expansion_voxels = [expansion_mm / spacing for spacing in voxel_spacing]\n",
    "    \n",
    "    # Calculate structure element size for dilation\n",
    "    # Using spherical structuring element for uniform expansion\n",
    "    radius = max(expansion_voxels)\n",
    "    struct_size = int(2 * radius + 1)\n",
    "    \n",
    "    # Create spherical structuring element\n",
    "    struct = ndimage.generate_binary_structure(3, 1)\n",
    "    struct = ndimage.iterate_structure(struct, int(radius))\n",
    "    \n",
    "    # Dilate the mask\n",
    "    expanded_mask = ndimage.binary_dilation(mask, structure=struct).astype(np.int16)\n",
    "    \n",
    "    return expanded_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e1e70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_mask(original_mask, expanded_mask, max_expansion_mm, voxel_spacing):\n",
    "\n",
    "    # Create a mask of the expansion region (difference between expanded and original)\n",
    "    expansion_region = expanded_mask.astype(int) - original_mask.astype(int)\n",
    "    \n",
    "    # Generate random values between 0 and max_expansion_mm for each voxel\n",
    "    random_values = np.random.uniform(0, max_expansion_mm, size=expansion_region.shape)\n",
    "    \n",
    "    # Create distance map from the original mask boundary\n",
    "    # (distance of each voxel in the expansion region from the original mask)\n",
    "    distance_map = ndimage.distance_transform_edt(~original_mask.astype(bool), sampling=voxel_spacing)\n",
    "    \n",
    "    # Only consider distances in the expansion region\n",
    "    distance_map = distance_map * expansion_region\n",
    "    \n",
    "    # Where the random value is less than the distance, keep the voxel in the randomized mask\n",
    "    # This ensures we don't exceed the max expansion and don't go below the original mask\n",
    "    random_mask = np.logical_or(\n",
    "        original_mask.astype(bool),\n",
    "        np.logical_and(\n",
    "            expansion_region.astype(bool),\n",
    "            random_values > distance_map\n",
    "        )\n",
    "    ).astype(np.int16)\n",
    "    \n",
    "    return random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d663ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def process_segmentation(input_file, expansion_mm=2.0, make_random=True):\n",
    "\n",
    "    # Extract filename parts\n",
    "    base_name = os.path.basename(input_file)\n",
    "    base_dir = os.path.dirname(input_file)\n",
    "    name_without_ext = os.path.splitext(base_name)[0]\n",
    "    if name_without_ext.endswith('.nii'):\n",
    "        name_without_ext = os.path.splitext(name_without_ext)[0]\n",
    "    \n",
    "    # Load the segmentation mask\n",
    "    mask_data, affine, header = load_nii(input_file)\n",
    "    \n",
    "    # Get voxel spacing from the affine matrix\n",
    "    voxel_spacing = np.array([abs(affine[i, i]) for i in range(3)])\n",
    "    \n",
    "    # Create output filenames\n",
    "    expanded_output = os.path.join(base_dir, f\"{name_without_ext}_expanded_{expansion_mm}mm.nii.gz\")\n",
    "    random_output = os.path.join(base_dir, f\"{name_without_ext}_random_{expansion_mm}mm.nii.gz\")\n",
    "    \n",
    "    # Expand the mask\n",
    "    expanded_mask = expand_mask(mask_data, expansion_mm, voxel_spacing)\n",
    "    \n",
    "    # Save expanded mask\n",
    "    save_nii(expanded_mask, affine, header, expanded_output)\n",
    "    \n",
    "    # Create and save randomized mask if requested\n",
    "    if make_random:\n",
    "        random_mask = randomize_mask(mask_data, expanded_mask, expansion_mm, voxel_spacing)\n",
    "        save_nii(random_mask, affine, header, random_output)\n",
    "        return expanded_output, random_output\n",
    "    \n",
    "    return expanded_output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97cdc434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing femur segmentation with 2.0mm expansion...\n",
      "Saved: segmented_femur_expanded_2.0mm.nii.gz\n",
      "Saved: segmented_femur_random_2.0mm.nii.gz\n",
      "Processing tibia segmentation with 2.0mm expansion...\n",
      "Saved: segmented_tibia_expanded_2.0mm.nii.gz\n",
      "Saved: segmented_tibia_random_2.0mm.nii.gz\n",
      "\n",
      "All processing complete!\n",
      "Expanded masks: segmented_femur_expanded_2.0mm.nii.gz, segmented_tibia_expanded_2.0mm.nii.gz\n",
      "Randomized masks: segmented_femur_random_2.0mm.nii.gz, segmented_tibia_random_2.0mm.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Process femur segmentation\n",
    "    femur_file = \"segmented_femur.nii.gz\"\n",
    "    expansion_mm = 2.0  # 2mm expansion parameter\n",
    "    \n",
    "    print(f\"Processing femur segmentation with {expansion_mm}mm expansion...\")\n",
    "    femur_expanded, femur_random = process_segmentation(femur_file, expansion_mm)\n",
    "    \n",
    "    # Process tibia segmentation\n",
    "    tibia_file = \"segmented_tibia.nii.gz\"\n",
    "    \n",
    "    print(f\"Processing tibia segmentation with {expansion_mm}mm expansion...\")\n",
    "    tibia_expanded, tibia_random = process_segmentation(tibia_file, expansion_mm)\n",
    "    \n",
    "    print(\"\\nAll processing complete!\")\n",
    "    print(f\"Expanded masks: {femur_expanded}, {tibia_expanded}\")\n",
    "    print(f\"Randomized masks: {femur_random}, {tibia_random}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aef12c",
   "metadata": {},
   "source": [
    "TASK 1.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1260f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_segmentation(file_path):\n",
    "    \"\"\"Load segmentation mask from NIfTI file.\"\"\"\n",
    "    print(f\"Loading: {file_path}\")\n",
    "    return nib.load(file_path)\n",
    "\n",
    "def save_segmentation(data, affine, output_path):\n",
    "    \"\"\"Save segmentation mask as NIfTI file.\"\"\"\n",
    "    nib_img = nib.Nifti1Image(data, affine)\n",
    "    nib.save(nib_img, output_path)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9d0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mask(mask_data, distance_mm, voxel_spacing):\n",
    "    \"\"\"Expand segmentation mask uniformly by specified distance in mm.\"\"\"\n",
    "    # Convert distance from mm to voxels\n",
    "    distance_voxels = [distance_mm / spacing for spacing in voxel_spacing]\n",
    "    \n",
    "    # Create structuring element for dilation\n",
    "    radius = int(max(distance_voxels))\n",
    "    struct = ndimage.generate_binary_structure(3, 1)\n",
    "    struct = ndimage.iterate_structure(struct, radius)\n",
    "    \n",
    "    # Dilate the mask\n",
    "    expanded_mask = ndimage.binary_dilation(mask_data, structure=struct).astype(mask_data.dtype)\n",
    "    \n",
    "    return expanded_mask\n",
    "\n",
    "def randomize_mask(original_mask, expanded_mask, random_seed=42):\n",
    "    \"\"\"Create randomized mask between original and expanded mask.\"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Find the boundary region (difference between expanded and original)\n",
    "    boundary = expanded_mask.astype(int) - original_mask.astype(int)\n",
    "    boundary_indices = np.where(boundary > 0)\n",
    "    \n",
    "    # Generate random values for boundary voxels\n",
    "    num_boundary_voxels = len(boundary_indices[0])\n",
    "    random_values = np.random.random(num_boundary_voxels)\n",
    "    \n",
    "    # Create a copy of the original mask for the randomized result\n",
    "    randomized_mask = np.copy(original_mask)\n",
    "    \n",
    "    # Randomly include some boundary voxels (approx 50%)\n",
    "    for i in range(num_boundary_voxels):\n",
    "        if random_values[i] > 0.5:\n",
    "            x, y, z = boundary_indices[0][i], boundary_indices[1][i], boundary_indices[2][i]\n",
    "            randomized_mask[x, y, z] = 1\n",
    "    \n",
    "    return randomized_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04c43150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_mask(segmentation_data):\n",
    "    \"\"\"Extract binary mask from segmentation (any non-zero value).\"\"\"\n",
    "    return (segmentation_data > 0).astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a4e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_landmarks(tibia_mask, voxel_spacing):\n",
    "    \"\"\"\n",
    "    Detect medial and lateral lowest points on tibial surface.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (medial_point, lateral_point) as (x, y, z) coordinates in mm\n",
    "    \"\"\"\n",
    "    # Get indices of all tibia voxels\n",
    "    tibia_indices = np.where(tibia_mask > 0)\n",
    "    \n",
    "    if len(tibia_indices[0]) == 0:\n",
    "        print(\"Warning: Empty mask, cannot detect landmarks\")\n",
    "        return (0, 0, 0), (0, 0, 0)\n",
    "    \n",
    "    # Find the lowest points (in superior-inferior direction, typically z-axis in medical imaging)\n",
    "    min_z = np.min(tibia_indices[2])\n",
    "    \n",
    "    # Get all points at the lowest z level\n",
    "    lowest_points_indices = [(tibia_indices[0][i], tibia_indices[1][i], tibia_indices[2][i]) \n",
    "                             for i in range(len(tibia_indices[0])) \n",
    "                             if tibia_indices[2][i] == min_z]\n",
    "    \n",
    "    if not lowest_points_indices:\n",
    "        print(\"Warning: Could not find lowest points\")\n",
    "        return (0, 0, 0), (0, 0, 0)\n",
    "    \n",
    "    # Sort points by x coordinate (lateral-medial axis)\n",
    "    lowest_points_indices.sort(key=lambda p: p[0])\n",
    "    \n",
    "    # The most medial and lateral points will be at the extremes of the sorted list\n",
    "    lateral_point_indices = lowest_points_indices[0]  # Smallest x (left/lateral)\n",
    "    medial_point_indices = lowest_points_indices[-1]  # Largest x (right/medial)\n",
    "    \n",
    "    # Convert from voxel indices to mm coordinates\n",
    "    lateral_point_mm = tuple(idx * spacing for idx, spacing in zip(lateral_point_indices, voxel_spacing))\n",
    "    medial_point_mm = tuple(idx * spacing for idx, spacing in zip(medial_point_indices, voxel_spacing))\n",
    "    \n",
    "    return medial_point_mm, lateral_point_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9177c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surface_points(mask_data):\n",
    "    \"\"\"Extract the surface points of a 3D binary mask.\"\"\"\n",
    "    # Create a structure for erosion\n",
    "    struct = ndimage.generate_binary_structure(3, 1)\n",
    "    \n",
    "    # Erode the mask\n",
    "    eroded = ndimage.binary_erosion(mask_data, structure=struct)\n",
    "    \n",
    "    # The surface is the difference between the original and eroded mask\n",
    "    surface = mask_data.astype(int) - eroded.astype(int)\n",
    "    \n",
    "    return surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26785e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: segmented_tibia_random_2.0mm.nii.gz\n",
      "Loaded tibia mask with shape: (512, 512, 216), voxel spacing: (0.869141, 0.869141, 2.0)\n",
      "Generating masks...\n",
      "Saving masks...\n",
      "Saved: tibia_landmarks\\original_mask.nii.gz\n",
      "Saved: tibia_landmarks\\expanded_2mm_mask.nii.gz\n",
      "Saved: tibia_landmarks\\expanded_4mm_mask.nii.gz\n",
      "Saved: tibia_landmarks\\randomized_mask_1.nii.gz\n",
      "Saved: tibia_landmarks\\randomized_mask_2.nii.gz\n",
      "Detecting landmarks...\n",
      "\n",
      "Landmark Coordinates (in mm):\n",
      "--------------------------------------------------------------------------------\n",
      "Mask Type            Medial Point                   Lateral Point                 \n",
      "--------------------------------------------------------------------------------\n",
      "Original Mask        (320.71, 238.14, 0.00)         (317.24, 242.49, 0.00)        \n",
      "2mm Expanded Mask    (322.45, 238.14, 0.00)         (315.50, 242.49, 0.00)        \n",
      "4mm Expanded Mask    (324.19, 238.14, 0.00)         (313.76, 242.49, 0.00)        \n",
      "Randomized Mask 1    (321.58, 255.53, 0.00)         (315.50, 242.49, 0.00)        \n",
      "Randomized Mask 2    (322.45, 238.14, 0.00)         (315.50, 242.49, 0.00)        \n",
      "--------------------------------------------------------------------------------\n",
      "All masks saved to 'tibia_landmarks' directory and landmarks detected.\n",
      "Landmark coordinates saved to 'tibia_landmarks\\landmark_coordinates.txt'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # File paths \n",
    "    input_tibia_file = \"segmented_tibia_random_2.0mm.nii.gz\"  # Using your existing file\n",
    "    output_dir = \"tibia_landmarks\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Parameters\n",
    "    expansion_distance_1 = 2.0  # mm\n",
    "    expansion_distance_2 = 4.0  # mm\n",
    "    \n",
    "    # Load tibia segmentation\n",
    "    tibia_img = load_segmentation(input_tibia_file)\n",
    "    tibia_data = tibia_img.get_fdata()\n",
    "    voxel_spacing = tibia_img.header.get_zooms()[:3]  # Get voxel dimensions in mm\n",
    "    \n",
    "    # Convert to binary mask if needed\n",
    "    original_mask = get_binary_mask(tibia_data)\n",
    "    \n",
    "    print(f\"Loaded tibia mask with shape: {original_mask.shape}, voxel spacing: {voxel_spacing}\")\n",
    "    \n",
    "    # Generate required masks\n",
    "    print(\"Generating masks...\")\n",
    "    expanded_mask_2mm = expand_mask(original_mask, expansion_distance_1, voxel_spacing)\n",
    "    expanded_mask_4mm = expand_mask(original_mask, expansion_distance_2, voxel_spacing)\n",
    "    \n",
    "    # We'll create additional randomized masks as needed\n",
    "    randomized_mask_1 = randomize_mask(original_mask, expanded_mask_2mm, random_seed=42)\n",
    "    randomized_mask_2 = randomize_mask(original_mask, expanded_mask_2mm, random_seed=123)\n",
    "    \n",
    "    # Save all masks\n",
    "    print(\"Saving masks...\")\n",
    "    save_segmentation(original_mask, tibia_img.affine, os.path.join(output_dir, \"original_mask.nii.gz\"))\n",
    "    save_segmentation(expanded_mask_2mm, tibia_img.affine, os.path.join(output_dir, \"expanded_2mm_mask.nii.gz\"))\n",
    "    save_segmentation(expanded_mask_4mm, tibia_img.affine, os.path.join(output_dir, \"expanded_4mm_mask.nii.gz\"))\n",
    "    save_segmentation(randomized_mask_1, tibia_img.affine, os.path.join(output_dir, \"randomized_mask_1.nii.gz\"))\n",
    "    save_segmentation(randomized_mask_2, tibia_img.affine, os.path.join(output_dir, \"randomized_mask_2.nii.gz\"))\n",
    "    \n",
    "    # Detect landmarks for all masks\n",
    "    print(\"Detecting landmarks...\")\n",
    "    masks = {\n",
    "        \"Original Mask\": original_mask,\n",
    "        \"2mm Expanded Mask\": expanded_mask_2mm, \n",
    "        \"4mm Expanded Mask\": expanded_mask_4mm,\n",
    "        \"Randomized Mask 1\": randomized_mask_1,\n",
    "        \"Randomized Mask 2\": randomized_mask_2\n",
    "    }\n",
    "    \n",
    "    # Store landmark coordinates for each mask\n",
    "    landmark_results = {}\n",
    "    \n",
    "    print(\"\\nLandmark Coordinates (in mm):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Mask Type':<20} {'Medial Point':<30} {'Lateral Point':<30}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for mask_name, mask_data in masks.items():\n",
    "        medial_point, lateral_point = detect_landmarks(mask_data, voxel_spacing)\n",
    "        landmark_results[mask_name] = {\n",
    "            \"medial_point\": medial_point,\n",
    "            \"lateral_point\": lateral_point\n",
    "        }\n",
    "        \n",
    "        # Format points for display with rounded values\n",
    "        medial_point_str = f\"({medial_point[0]:.2f}, {medial_point[1]:.2f}, {medial_point[2]:.2f})\"\n",
    "        lateral_point_str = f\"({lateral_point[0]:.2f}, {lateral_point[1]:.2f}, {lateral_point[2]:.2f})\"\n",
    "        \n",
    "        print(f\"{mask_name:<20} {medial_point_str:<30} {lateral_point_str:<30}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"All masks saved to '{output_dir}' directory and landmarks detected.\")\n",
    "    \n",
    "    # Save landmark coordinates to a file for submission\n",
    "    with open(os.path.join(output_dir, \"landmark_coordinates.txt\"), \"w\") as f:\n",
    "        f.write(\"Tibia Landmark Coordinates (in mm)\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"{'Mask Type':<20} {'Medial Point':<30} {'Lateral Point':<30}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        \n",
    "        for mask_name, points in landmark_results.items():\n",
    "            medial = points[\"medial_point\"]\n",
    "            lateral = points[\"lateral_point\"]\n",
    "            \n",
    "            medial_str = f\"({medial[0]:.2f}, {medial[1]:.2f}, {medial[2]:.2f})\"\n",
    "            lateral_str = f\"({lateral[0]:.2f}, {lateral[1]:.2f}, {lateral[2]:.2f})\"\n",
    "            \n",
    "            f.write(f\"{mask_name:<20} {medial_str:<30} {lateral_str:<30}\\n\")\n",
    "    \n",
    "    print(f\"Landmark coordinates saved to '{os.path.join(output_dir, 'landmark_coordinates.txt')}'\")\n",
    "    \n",
    "    return landmark_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f0352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
